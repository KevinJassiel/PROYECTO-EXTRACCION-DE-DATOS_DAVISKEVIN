from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from bs4 import BeautifulSoup
import pandas as pd
from webdriver_manager.chrome import ChromeDriverManager

# con esta linea se descarga en automatico el webdriver, sin necesidad de colocar rutas de ningun tipo
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))

# tengo que guardar la ruta de la pgaina de los datos extraidos
url = "https://www.imdb.com/chart/top/?ref_=nv_mv_250"

# abre la pagina web
driver.get(url)

# Listas para almacenar los datos, todas estan sin ningun dato por el momento
nombres_peliculas = []
año_peliculas = []
duracion_peliculas = []
clasificacion_peliculas = []
calificacion_peliculas = []

# es el lapso de lo que tardara en cargar la pagina, puedo procurar no poner un numero tancorto por que lo detectan como bot
time.sleep(5)

html = driver.page_source
html = html.encode('utf-8').decode('utf-8')

#creo el objeto
soup = BeautifulSoup(html, 'html.parser')




#busca todos los elementos dentro una linea de codigo, en este caso el rectangulo con toda la informacion
pelis = soup.find_all('div', class_='ipc-metadata-list-summary-item__c')

#cabe recalcar que al obtener la informacion tuve un error ya que los datos de las variables
#duracion, clasificcion y año se encuentran en una misma linea de codigo, tanto si class como que sean tipo span afecto
#al extraer la informacion solo obtuve bien el de los años, se elpor que pero no supe orgnizar esto por mas intentos que realice
#los demas se duplicaron con el los años, por eso trabaje con lo que obtuve correctamente NOMBRE,AÑO,CALIFICACION


#EXTRAER los datos del codigo de la pagina
for producto in pelis:
    nombre = producto.find('h3', class_='ipc-title__text').text.strip()
    año = producto.find('span', class_='sc-300a8231-7 eaXxft cli-title-metadata-item').text.strip()
    duracion = producto.find('span', class_='sc-300a8231-7 eaXxft cli-title-metadata-item').text.strip()
    clasificacion = producto.find('span', class_='sc-300a8231-7 eaXxft cli-title-metadata-item').text.strip()
    calificacion = producto.find('span', class_='ipc-rating-star--rating').text.strip()

# Guardar los datos extraidos
    nombres_peliculas.append(nombre)
    año_peliculas.append(año)
    duracion_peliculas.append(duracion)
    clasificacion_peliculas.append(clasificacion)
    calificacion_peliculas.append(calificacion)


# Cerrar el navegador
driver.quit()

#lo tuve que guardar en un getter para que me dejara insertarlo al base de datos mysql
def get_data():
    return productos_df


# se crea el dataframe con los datos de la pagina
productos_df = pd.DataFrame({
    'Nombre': nombres_peliculas,
    'año': año_peliculas,
    'duracion': duracion_peliculas,
    'clasificacion': clasificacion_peliculas,
    'calificacion': calificacion_peliculas
})

# estuve guardando los archivos en un csv para ir comprobando los datos extraidos
productos_df.to_csv('pelis4.csv', index=False,encoding='utf-8')

print("Datos extraídos y guardados correctamente.")
